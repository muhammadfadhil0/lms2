# Document Chunking System - Setup Instructions

## üìã Sistem Document Chunking untuk Optimasi Token AI

Sistem ini memecah dokumen besar menjadi chunks kecil (500-1000 kata) dan hanya mengirim bagian yang relevan ke AI, menghemat hingga 80% token usage.

## üîß Setup Instructions

### 1. Database Setup
```sql
-- Jalankan file SQL berikut di database Anda:
mysql -u root -p lms < database/document-chunks-schema.sql
```

### 2. PHP Dependencies
Pastikan ekstensi PHP berikut tersedia:
- `pdo_mysql` - untuk database
- `zip` - untuk DOCX processing  
- `mbstring` - untuk text encoding
- Composer autoloader sudah ada (untuk PDF parser)

### 3. Directory Permissions
```bash
# Buat directory upload jika belum ada
mkdir -p uploads/documents
chmod 755 uploads/documents

# Pastikan web server dapat menulis ke directory tersebut
chown -R www-data:www-data uploads/
```

### 4. File Structure
```
src/
‚îú‚îÄ‚îÄ classes/
‚îÇ   ‚îú‚îÄ‚îÄ DocumentChunker.php          # Core chunking logic
‚îÇ   ‚îî‚îÄ‚îÄ AIQueryOptimizer.php         # AI query optimization
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ document-chunking-api.php    # REST API endpoints
‚îú‚îÄ‚îÄ script/
‚îÇ   ‚îú‚îÄ‚îÄ document-chunking.js         # Frontend chunking system
‚îÇ   ‚îî‚îÄ‚îÄ pingo-chunking-integration.js # PingoChat integration
‚îî‚îÄ‚îÄ database/
    ‚îî‚îÄ‚îÄ document-chunks-schema.sql   # Database schema
```

## üöÄ How It Works

### Upload Process
1. **File Upload** ‚Üí Document Chunking System
2. **Text Extraction** ‚Üí PDF/DOCX/TXT parser
3. **Smart Chunking** ‚Üí 500-1000 kata per chunk dengan overlap
4. **Keyword Extraction** ‚Üí Untuk relevance scoring
5. **Database Storage** ‚Üí Chunks disimpan dengan metadata

### Query Process  
1. **User Query** ‚Üí Keyword extraction
2. **Chunk Search** ‚Üí Full-text search + keyword matching
3. **Top 3 Chunks** ‚Üí Berdasarkan relevance score
4. **Context Building** ‚Üí Gabung chunks jadi context
5. **AI Query** ‚Üí Kirim hanya bagian relevan (~2000 tokens vs 15000+)

## üìä Token Optimization Results

| Document Size | Before Chunking | After Chunking | Savings |
|--------------|----------------|---------------|---------|
| 10 halaman   | ~15,000 tokens | ~3,000 tokens | 80% ‚¨áÔ∏è |
| 25 halaman   | ~35,000 tokens | ~3,500 tokens | 90% ‚¨áÔ∏è |
| 50 halaman   | ~70,000 tokens | ~4,000 tokens | 94% ‚¨áÔ∏è |

## üõ†Ô∏è API Endpoints

### Upload Document
```javascript
POST /src/api/document-chunking-api.php
Content-Type: multipart/form-data

{
  "action": "upload_document",
  "document": File
}
```

### Search Chunks  
```javascript
POST /src/api/document-chunking-api.php
Content-Type: application/json

{
  "action": "search_chunks", 
  "document_id": 123,
  "query": "user question",
  "limit": 3
}
```

### Get Document Status
```javascript
GET /src/api/document-chunking-api.php?action=get_processing_status&document_id=123
```

## üí° Usage Examples

### JavaScript Integration
```javascript
// Upload document with chunking
const result = await window.documentChunking.handleDocumentUpload(file);

// Get current document IDs  
const docIds = window.documentChunking.getCurrentDocumentIds();

// Create optimized AI content
const optimized = await window.documentChunking.createOptimizedAIContent(
    docIds, 
    userQuestion, 
    systemPrompt
);

// Send to AI (already integrated with PingoChat)
```

### PHP Backend Usage
```php
// Process document
$chunker = new DocumentChunker();
$result = $chunker->processDocument($filePath, $filename, $userId);

// Find relevant chunks
$chunks = $chunker->findRelevantChunks($docId, $userQuery, 3);

// Optimize AI query
$optimizer = new AIQueryOptimizer();
$optimized = $optimizer->optimizeDocumentQuery($docIds, $userQuery);
```

## üéØ Features

### ‚úÖ Smart Chunking
- **Sentence-aware splitting** - Tidak memotong di tengah kalimat
- **Overlap mechanism** - 50 kata overlap untuk konteks
- **Keyword extraction** - Otomatis extract keywords untuk search
- **Multiple formats** - PDF, DOCX, TXT support

### ‚úÖ Efficient Search  
- **Full-text search** - MySQL FULLTEXT index
- **Keyword matching** - Weighted keyword relevance
- **Fallback strategy** - Ambil chunk pertama jika no match
- **Relevance scoring** - Combine content + keyword scores

### ‚úÖ UI Integration
- **Progress indicators** - Real-time upload progress
- **Visual feedback** - Success/error notifications  
- **Thumbnail system** - Chunked document indicators
- **Seamless integration** - Works with existing PingoChat

### ‚úÖ Error Handling
- **Rate limit detection** - Smart error messages
- **Fallback mechanisms** - Graceful degradation
- **User-friendly errors** - Tidak show technical errors
- **Retry logic** - Automatic retry untuk transient errors

## üîç Troubleshooting

### Common Issues

**1. "Unable to extract text from document"**
- Check file format (PDF/DOCX/TXT only)
- Ensure file not corrupted
- Verify PDF is not image-only

**2. "Processing failed"**  
- Check database connection
- Verify upload directory permissions
- Check PHP memory limit (increase if needed)

**3. "No relevant chunks found"**
- Document mungkin belum selesai di-process
- Query terlalu spesifik, coba query lebih general
- Check database ada chunks untuk document

**4. Rate limit errors**
- System akan show user-friendly message
- Wait time otomatis di-parse dari error
- Chunks membantu reduce token usage

### Database Maintenance
```sql  
-- Check chunking statistics
SELECT 
    COUNT(*) as total_documents,
    SUM(total_chunks) as total_chunks,
    AVG(total_words) as avg_words_per_doc
FROM documents 
WHERE processing_status = 'completed';

-- Clean old documents (30+ days)
DELETE FROM documents 
WHERE upload_date < DATE_SUB(NOW(), INTERVAL 30 DAY);
```

## üöÄ Performance Tips

1. **Batch Processing** - Process multiple files saat traffic rendah
2. **Cache Results** - Use query cache untuk repeated queries  
3. **Index Optimization** - Ensure FULLTEXT indexes optimal
4. **Memory Management** - Monitor PHP memory usage untuk large files
5. **Background Processing** - Consider queue system untuk large uploads

## üìà Monitoring & Analytics

Track these metrics untuk system health:
- Average chunks per document
- Query response times  
- Token savings percentage
- Error rates by file type
- User engagement dengan chunked docs

## üîí Security Considerations

- File type validation (whitelist only)
- File size limits (10MB default)
- User authentication required
- SQL injection protection (prepared statements)
- XSS protection (HTML escaping)

---

**‚úÖ System Ready!** Upload dokumen dan lihat dramatic token savings! üéâ